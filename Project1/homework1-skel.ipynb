{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NAME: Nigel Mansell\n",
    "\n",
    "# Homework 1\n",
    "\n",
    "### Objectives\n",
    "* Basic numpy operations to access data\n",
    "* Basic plotting of subsets of data\n",
    "* Simple descriptive statistics\n",
    "* Do not save work within the mlp_2020 folder\n",
    "  + create a folder in your home directory for assignments, and copy the templates there  \n",
    "\n",
    "### General References\n",
    "* [Sci-kit Learn Iris Dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html)\n",
    "* [Numpy Reference](https://docs.scipy.org/doc/numpy/reference/index.html)\n",
    "* [Summary of matplotlib](https://matplotlib.org/3.1.1/api/pyplot_summary.html)\n",
    "  + [Plot](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.plot.html)\n",
    "  + [Boxplots](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.boxplot.html)\n",
    "  + [Histograms](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.hist.html#matplotlib.pyplot.hist)\n",
    "  + [Scatter plots](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.scatter.html#matplotlib.pyplot.scatter)\n",
    "  + [Colormap Plots](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.imshow.html)\n",
    "\n",
    "### Hand-In Procedure\n",
    "* Execute all cells so they are showing correct results\n",
    "* Notebook:\n",
    "  + Submit this file (.ipynb) to the Canvas HW1 dropbox\n",
    "* PDF:\n",
    "  + File/Export Notebook As/PDF -> Produces a copy of the notebook in PDF format\n",
    "  + Submit the PDF file to the Gradescope HW1 dropbox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import get_ipython\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD IRIS DATA SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the dataset into the iris_dataset variable, by calling the \n",
    "load_iris() function imported from sklearn.datasets.\n",
    "Then display the iris_dataset object's list of keys. iris_dataset\n",
    "is a dictionary object.\n",
    "\"\"\"\n",
    "\n",
    "\"laoding the data and printing the keys\"\n",
    "iris_dataset = load_iris()\n",
    "iris_dataset.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Details\n",
    "The `iris_dataset` variable is a dictionary with multiple fields:\n",
    "* `data` : m by n numpy array of the n observed feature values, for each of the m samples  \n",
    "* `target` : m by 1 numpy array of samples' classification as iris-setosa (i.e. 0), iris-versicolour (i.e. 1), or iris-virginica (i.e. 2)\n",
    "* `target_names` : 3 by 1 numpy array of the possible iris classifications  \n",
    "* `DESCR` : string containing a detailed description of the dataset  \n",
    "* `feature_names` : n by 1 numpy array of the names of the feature variables  \n",
    "* `filename` : string containing the absolute path to where the file containing all the data information is located on the local system  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Print out the description of the data, by accessing the \n",
    "'DESCR' field of the iris data set\n",
    "\"\"\"\n",
    "\n",
    "\"Printing the discription from its key\"\n",
    "print(iris_dataset['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP USEFUL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Store the names of the features and the names \n",
    "of the target classes, into the variables\n",
    "feature_names and target_names respectively.\n",
    "\"\"\"\n",
    "\n",
    "\"seting feature and target names to their associated keys\"\n",
    "feature_names =  iris_dataset['feature_names']\n",
    "target_names = iris_dataset['target_names']\n",
    "\n",
    "\"\"\"\n",
    "Print the list of feature names and target names\n",
    "\"\"\"\n",
    "\n",
    "\"printing feature and target names\"\n",
    "print(feature_names)\n",
    "print(target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Create variables for the feature and target data \n",
    "The X variable is a numpy array containing the data measured \n",
    "for each feature for each sample. Each column of X is a \n",
    "different feature for all the samples. Each row of X is a \n",
    "different sample with all its features.\n",
    "The y variable is a numpy array containing the classification \n",
    "for each sample. A sample iris is either setosa, versicolor, or virginica.\n",
    "\"\"\" \n",
    "\n",
    "\"setting X to the data from the key data and y to data from target\"\n",
    "X = iris_dataset['data']\n",
    "y = iris_dataset['target']\n",
    "\n",
    "\"\"\"\n",
    "Print the dimensions of the X and y variables respectively\n",
    "\"\"\"\n",
    "\n",
    "\"printing both x and y dimensions\"\n",
    "print(X.ndim)\n",
    "print(y.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Store the number of samples and the number of features, by\n",
    "accessing the values from the shape of X\n",
    "\"\"\"\n",
    "\n",
    "\"setting nsamples to the row of X and nfeatures to the column of X\"\n",
    "nsamples, nfeatures = X.shape\n",
    "\n",
    "\"\"\"\n",
    "Print the print the number of samples and numberof features respectively\n",
    "\"\"\"\n",
    "\n",
    "\"printing nsamples and nfeatures\"\n",
    "print(nsamples)\n",
    "print(nfeatures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SELECT SUBSET OF FEATURES\n",
    "Not all available data is necessary or useful for making predictions and classifying observations. There are numerous feature selection algorithms that exist, which will be discussed in more detail later within the cousre. For now we are going to arbitrarly select sepal length, sepal width and petal length as our predictor variables. We will not yet be performing any predictions in this assignment; rather this term is used to conveniently distinuguish this subset of features from the full set of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Feature Column Indices\n",
    "The values observed for each feature resides within a particular \n",
    "column of the feature matrix, X. For example, column 0 contains the \n",
    "values of the mean radius for each observation, the column at index \n",
    "3 contains the values for the mean area, and so on.\n",
    "\"\"\"\n",
    "sepal_length_idx = 0\n",
    "sepal_width_idx = 1\n",
    "petal_length_idx = 2\n",
    "\n",
    "\"\"\"\n",
    "Create a list of the select subset of features\n",
    "\"\"\"\n",
    "predictors = [sepal_length_idx, sepal_width_idx, petal_length_idx]\n",
    "\n",
    "\"\"\"\n",
    "Create a variable, storing the number of predictors\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"the length of predictors\"\n",
    "predictorSize = len(predictors)\n",
    "\n",
    "\"\"\"\n",
    "Create a list of corresponding names for the selected set of features.\n",
    "This is conveniently done using list comprehension\n",
    "\"\"\"\n",
    "\n",
    "\"the names of the predictors from feature_names array\"\n",
    "predictorNames = [feature_names[i] for i in range(predictorSize)]\n",
    "\"\"\"\n",
    "Print the list of predictor names\n",
    "\"\"\"\n",
    "\n",
    "\"prints the names\"\n",
    "print(predictorNames)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASIC HISTOGRAMS OF FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "HISTOGRAMS OF THE CHOSEN PREDICTOR FEATURES\n",
    "Please plot histograms in their own subplot of \n",
    "the same figure.\n",
    "\"\"\"\n",
    "\n",
    "\"Turned X into a dataframe in order to iterate over columns easier\"\n",
    "df = pd.DataFrame(data=X,index=None,columns=feature_names)\n",
    "plt.figure(figsize=(20,4))\n",
    "plt.subplots_adjust(wspace=.3)\n",
    "for i, fidx in enumerate(predictors, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    plt.title(predictorNames[fidx])\n",
    "    df[predictorNames[fidx]].hist()\n",
    "    # TODO: Plot the histogram \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Create a histogram or barplot for the counts\n",
    "for each target class\n",
    "\"\"\"\n",
    "\n",
    "\"creates 3 histograms for each class and displays their count, or how often they appear\"\n",
    "for i in y:\n",
    "    plt.figure(i+1)\n",
    "    plt.title(target_names[i])\n",
    "    plt.hist(y, bins=np.arange(0, 51))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASIC BOXPLOTS OF FEATURES\n",
    "Boxplots or box-and-whisker plots are used to obtain a perspective of the distribution of the data.\n",
    "The box within the figure displays the 25th percentile (Q1), the median, and the 75th percentile (Q3) of the data. The range between the 75th percentile value and the 25th percentile value is the interquartile range (IQR = Q3 - Q1). The end of bottom line is Q1 - 1.5 * IQR. The end of top line is Q3 + 1.5 * IQR. Anything beyond the lines, the circles, are suggested outliers.  \n",
    "<center><img src=\"boxplot_diagram.png\" style=\"width:30%;height:30%\"><\\center>\n",
    "\n",
    "One can use the `boxplot(data_values, labels=[name])` to generate a boxplot. `data_values` would be the set of observed values for a paritucular feature and `labels` should be provided as a list, with the name of the feature, in place of `name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "BOXPLOTS OF THE CHOSEN PREDICTOR FEATURES\n",
    "Please place the boxplots within their own \n",
    "subplot of the same figure \n",
    "\"\"\"\n",
    "\n",
    "\"Creates boxplots for predictors\"\n",
    "plt.subplots_adjust(wspace=.5)\n",
    "for i, fidx in enumerate(predictors, 1):\n",
    "    plt.subplot(1, 3, i)\n",
    "    df.boxplot(column=predictorNames[fidx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DESCRIPTIVE STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simply run this cell\n",
    "\"\"\" \n",
    "Create a separate variable of the data from the \n",
    "predictors\n",
    "\"\"\"\n",
    "Xpreds = X[:, predictors]\n",
    "\n",
    "\"\"\"\n",
    "Check if any values are NaN (not a number)\n",
    "\"\"\"\n",
    "np.any(np.isnan(Xpreds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" TODO\n",
    "Compute the following descriptive statistics of the \n",
    "features ignoring NaN values, using numpy:\n",
    "mean, median, standard deviation, min, and max\n",
    "\n",
    "Make sure to compute the statistics of the columns\n",
    "of X (i.e. of each feature). You can specify this \n",
    "by setting axis=0 for each of the functions\n",
    "\n",
    "Compute and print the results\n",
    "\"\"\"\n",
    "\n",
    "\"Prints the non nan vales of each statistic\"\n",
    "print(\"Mean: \", np.nanmean(Xpreds, axis=0))\n",
    "print(\"Median: \", np.nanmedian(Xpreds, axis=0))\n",
    "print(\"Standard deviation: \", np.nanstd(Xpreds, axis=0))\n",
    "print(\"Min: \", np.nanmin(Xpreds, axis=0))\n",
    "print(\"Max: \", np.nanmax(Xpreds, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURE CORRELATIONS\n",
    "It's useful to know the correlation between various features, as well as each feature and the predicted label. Feature correlation is useful for feature selection and understanding the relationship between multiple variables within a dataset. Correlation is either positive, negative, or zero. When two features increase simultaneously, they are positively correlated. When one feature increases while the other decreases, the features are negatively correlated. Zero correlation is when there is no relationship between the features. Correlation is on the range -1 (perfect negative correlation) and 1 (pefect positive correlation).  \n",
    "We can construct scatter plots of one feature versuses another to observe linear or nonlinear relationships.\n",
    "\n",
    "Complete the following set of scatter plots:\n",
    "<center><img src=\"scatterplots.png\"  style=\"width:50%;height:50%\"><\\center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Using the scatter plot function, construct plots depicting the\n",
    "correlation between all pairings of the selected predictor features\n",
    "and between all predictors and the determined target.\n",
    "The figure will contain r by r subplots, where r = npredictors + 1.\n",
    "Where subplot(i,j) is a scatter plot of the feature i versus feature j.\n",
    "When i == j, plot the histogram of feature i instead of a scatter plot.\n",
    "We are also interested in the correlation between each of the features \n",
    "and the target classification, thus we will combine the predictors matrix\n",
    "and the target vector into one large matrix for convenience.\n",
    "\"\"\"\n",
    "# Append the y to the end of the matrix of predictors\n",
    "Xycombo = np.append(Xpreds, y.reshape(-1, 1), axis=1)\n",
    "# Append the name 'target' to the end of the list of predictor names\n",
    "Xycolnames = predictorNames + ['target']\n",
    "\n",
    "df_Xycombo = pd.DataFrame(data=Xycombo,index=None, columns=Xycolnames)\n",
    "# Create the scatter plots\n",
    "fig, axs = plt.subplots(predictorSize+1, predictorSize+1, figsize=(15, 15))\n",
    "fig.subplots_adjust(wspace=.35)\n",
    "for f1 in range(predictorSize+1):\n",
    "    for f2 in range(predictorSize+1): \n",
    "        if f1 == f2:\n",
    "            \"creates a histogram if feature1 and feature2 are equal\"\n",
    "            axs[f1][f2].hist(df_Xycombo[Xycolnames[f1]])\n",
    "        else:\n",
    "            \"scatter plots the difference between feature1 and feature2\"\n",
    "            axs[f1][f2].scatter(df_Xycombo[Xycolnames[f1]], df_Xycombo[Xycolnames[f2]])\n",
    "        if f1 == predictorSize:\n",
    "            axs[f1, f2].set_xlabel(Xycolnames[f2])\n",
    "        if f2 == 0:\n",
    "            axs[f1, f2].set_ylabel(Xycolnames[f1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGES AND COLORMAPS\n",
    "Create a colormap plot of the correlations between the \n",
    "all the predictors and the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" PROVIDED\n",
    "Generate a figure that plots the a correlation matrix\n",
    "as a colormap.\n",
    "PARAMS:\n",
    "    corrs: matrix of correlations between the features\n",
    "    varnames: list of the names of each of the features \n",
    "              (e.g. the column names)\n",
    "\"\"\"\n",
    "def correlationmap(corrs, varnames):\n",
    "    nvars = corrs.shape[0]\n",
    "    \n",
    "    # create the figure and plot the correlation matrix\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(corrs, cmap='RdBu', vmin=-1, vmax=1)\n",
    "    cbar = ax.figure.colorbar(im, ax=ax)\n",
    "    cbar.ax.set_ylabel(\"Pearson Correlation\", rotation=-90, va=\"bottom\")\n",
    "    \n",
    "    # Specify the row and column ticks and labels for the figure\n",
    "    ax.set_xticks(range(nvars))\n",
    "    ax.set_yticks(range(nvars))\n",
    "    ax.set_xticklabels(varnames)\n",
    "    ax.set_yticklabels(varnames)\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    for i in range(nvars):\n",
    "        for j in range(nvars):\n",
    "            text = ax.text(j, i, \"%.3f\" % corrs[i, j],\n",
    "                           ha=\"center\", va=\"center\", color=\"k\")\n",
    "# END DEF correlationmap\n",
    "            \n",
    "\n",
    "\"\"\" TODO\n",
    "Compute the Pearson correlation between the columns of Xycombo using\n",
    "the numpy function corrcoef(). The corrcoef() function performs the \n",
    "the pairwise correlation on the rows of a matrix, thus you will need to\n",
    "transpose the input.\n",
    "\"\"\" \n",
    "\n",
    "\"transposes Xycombo then is used in np.corrcoef\"\n",
    "Xycorrs = np.corrcoef(np.transpose(Xycombo))\n",
    "\n",
    "\"\"\" TODO\n",
    "Call the function defined above, correlationmap(), to generate a \n",
    "colormap plot of the correlations between columns of the Xycombo matrix\n",
    "\"\"\"\n",
    "\n",
    "\"calling correlationmap by passing Xycorrs and Xycolnames\"\n",
    "correlationmap(Xycorrs, Xycolnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
